{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding + CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. x_train: \\[text1, text2, ...\\]\n",
    "   y_train: \\[[label11, label12, ...], [label21, ...], ...\\]\n",
    "\n",
    "2. Generate vocabulary set and get token_to_id map. This map will map a word to an index in vocabulary space. Transform text to \\[index1, index2, ..., \\]. \n",
    "\n",
    "   Padded sequences to fixed length (750, )\n",
    "    \n",
    "3. Word Vector - Google News 300\n",
    "\n",
    "4. Do classification by CNN\n",
    "\n",
    "![](https://i.loli.net/2018/12/22/5c1df43d21bd7.jpg)\n",
    "\n",
    "5. Using MultilabelBinarizer mapping \\[label1, label2, ...\\] to [1,1,0,0,...,] by one-hot.\n",
    "\n",
    "The accuracy is 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'running_result/wordemb_cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess part\n",
    "\n",
    "We construct documents as $[d_1, d_2, ..., d_m]$ and labels as $[y_1, ..., y_m]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Extract data from pickle files ==========\n"
     ]
    }
   ],
   "source": [
    "from src.data_preprocess.preprocess import DataSet\n",
    "dataset = DataSet()\n",
    "raw_x_train, raw_y_train, raw_x_test, raw_y_test = dataset.get_train_and_test_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize document text into a list of tokens \\['u.s.', 'econom', 'data', 'debt', 'chicago', 'interest',...\\] using NLTK library and remove stop-words from tokens, such as \\['a', 'the', ...\\]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from src.data_preprocess.preprocess import stop_words_\n",
    "import re\n",
    "\n",
    "def convert_text_to_word_list(text: str) -> []:\n",
    "    word_tokens = word_tokenize(text)\n",
    "    tokens = []\n",
    "    for word in word_tokens:\n",
    "        # remove punctturation and stop word\n",
    "        word = word.replace('*', '')\n",
    "        if re.compile(r'[a-z]').search(word) is None or word in stop_words_ or len(word) <= 3:\n",
    "            continue\n",
    "        tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7310, 7310, 3353, 3353)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "x_train = []\n",
    "y_train = raw_y_train.copy()\n",
    "x_test = []\n",
    "y_test = []\n",
    "bag_of_classes = set()\n",
    "\n",
    "for i, x in enumerate(raw_x_train):\n",
    "    bag_of_classes = bag_of_classes.union(raw_y_train[i])\n",
    "    tokens = convert_text_to_word_list(x)\n",
    "    x_train.append(' '.join(tokens))\n",
    "        \n",
    "for i, x in enumerate(raw_x_test):\n",
    "    labels = [class_ for class_ in raw_y_test[i] if class_ in bag_of_classes]\n",
    "    if len(labels) == 0:\n",
    "        continue\n",
    "    tokens = convert_text_to_word_list(x)\n",
    "    x_test.append(' '.join(tokens))\n",
    "    y_test.append(labels)\n",
    "\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summit petroleum corp sells shares abilene texas march summit petroleum corp sold shares common stock halbert associates company shares previously held consolidated energy corp harken hogi addition david halbert president chief executive officer halbert abilene investment firm named chairman chief executive summit company halbert charles bruce james burke named directors expanding board summit added company burke president chief executive allied comprehensive health abilene bruce partner washington firm butler binion summit intends actively seek acquisitions increase asset base reuter'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_NUM_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token='UNK')\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7310, 730), (3353, 730))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 730\n",
    "\n",
    "data_train_X = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "data_test_X = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "data_train_X.shape, data_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3332,   230,    12,   704,    17,  9420,   296,     3,  3332,\n",
       "         230,    12,   203,    17,    69,    18,  8076,  1136,    10,\n",
       "          17,   211,   234,   774,   200,    12, 14861, 14862,   576,\n",
       "        1097,  8076,   106,   396,   327,   711,  8076,  9420,    85,\n",
       "         195,  1029,   129,   396,   327,  3332,    10,  8076,  1972,\n",
       "        4108,   759,  9421,  1029,   488,  2016,    53,  3332,    67,\n",
       "          10,  9421,   106,   396,   327,   967,  2830,   776,  9420,\n",
       "        4108,  1470,    57,   195,  4109, 14863,  3332,  1085,  2209,\n",
       "         548,   658,    62,  1099,   312,     4,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "lb = MultiLabelBinarizer()\n",
    "lb.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]), (3353, 88))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vector = lb.transform(y_train)\n",
    "y_test_vector = lb.transform(y_test)\n",
    "y_train_vector[::300], y_test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_vectors = [vector for vector in y_test_vector if sum(vector) > 1]\n",
    "len(multi_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_x, train_y, val_y = train_test_split(data_train_X, y_train_vector, test_size=1000, random_state=65)\n",
    "\n",
    "data_test_y = y_test_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build word vector matrix\n",
    "\n",
    "Using word2vec algorithm to train the word vector on document. We can get a dict {str: (300,)} as result.\n",
    "\n",
    "'spokesman': \\[-0.0147094, -0.05737305, 0.14257812, -0.29882812, 0.15527344, -0.28710938, 0.05151367, -0.03125, â€¦\\]\n",
    "\n",
    "Convert each document \"economy each year...\" -> (n, 300) word vector. Let n = 1500. Padding documents with fewer words than 1500. Now each document is (1500, 300) matrix and all document format as a (m, 1500, 300) tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Google News 300 dimension word vector\n",
    "from gensim.models import KeyedVectors\n",
    "filename = '~/gensim-data/GoogleNews-300/GoogleNews-vectors-negative300.bin'\n",
    "embedding_wv_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "EMBEDDING_DIM = embedding_wv_model.vector_size\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in embedding_wv_model.vocab:\n",
    "        embedding_matrix[i] = embedding_wv_model.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10351562,  0.16113281,  0.1171875 , -0.25390625,  0.00891113,\n",
       "        0.00823975,  0.10302734, -0.40039062,  0.09423828,  0.03063965,\n",
       "        0.0390625 ,  0.07958984, -0.03955078, -0.06494141, -0.13085938,\n",
       "        0.00976562, -0.08544922,  0.14160156,  0.17285156,  0.07910156,\n",
       "        0.03344727, -0.08935547, -0.01263428,  0.3046875 , -0.12060547,\n",
       "        0.2890625 , -0.12890625, -0.00561523,  0.01452637, -0.11181641,\n",
       "       -0.08398438, -0.02954102, -0.09472656,  0.10107422,  0.05859375,\n",
       "       -0.06225586,  0.05810547,  0.05224609,  0.07177734,  0.375     ,\n",
       "       -0.06030273, -0.14648438,  0.21484375,  0.05810547, -0.12890625,\n",
       "       -0.00793457, -0.14355469, -0.09521484, -0.1640625 ,  0.17675781,\n",
       "        0.09814453,  0.15625   , -0.01953125,  0.16601562,  0.06835938,\n",
       "       -0.08447266, -0.08056641, -0.26171875,  0.10107422, -0.13085938,\n",
       "       -0.04174805, -0.15722656, -0.19433594,  0.125     , -0.0043335 ,\n",
       "       -0.07373047, -0.13769531,  0.16503906, -0.19921875,  0.05102539,\n",
       "       -0.06738281, -0.24511719,  0.17773438, -0.21191406, -0.10253906,\n",
       "       -0.19433594,  0.22070312,  0.47460938, -0.203125  , -0.15429688,\n",
       "        0.203125  ,  0.06542969, -0.14160156,  0.0222168 ,  0.19726562,\n",
       "        0.07226562, -0.03735352,  0.20214844, -0.06787109, -0.04272461,\n",
       "        0.0016098 ,  0.05712891, -0.04418945, -0.05566406, -0.22753906,\n",
       "       -0.19824219, -0.11816406,  0.15234375, -0.01867676, -0.17382812,\n",
       "        0.07861328, -0.21777344,  0.13183594, -0.01098633,  0.08447266,\n",
       "       -0.10546875, -0.23535156, -0.06542969, -0.09130859, -0.06298828,\n",
       "       -0.15234375,  0.09277344, -0.09326172,  0.27929688, -0.0189209 ,\n",
       "        0.30273438,  0.1875    , -0.06884766,  0.10644531, -0.16113281,\n",
       "       -0.30664062, -0.22851562, -0.08007812, -0.16210938, -0.265625  ,\n",
       "       -0.1796875 ,  0.06738281, -0.13574219, -0.20800781, -0.02600098,\n",
       "       -0.11914062, -0.11914062, -0.02246094,  0.09667969,  0.05493164,\n",
       "        0.26757812,  0.06835938, -0.10205078, -0.1640625 ,  0.10205078,\n",
       "        0.05810547, -0.19824219, -0.28320312,  0.109375  ,  0.03662109,\n",
       "        0.08886719,  0.14746094,  0.19628906, -0.03417969, -0.03662109,\n",
       "       -0.01318359, -0.08740234,  0.07177734,  0.09765625,  0.15917969,\n",
       "        0.07177734,  0.38671875, -0.14453125, -0.01696777, -0.3984375 ,\n",
       "       -0.15820312,  0.27539062,  0.02734375,  0.31835938,  0.125     ,\n",
       "        0.25      , -0.2734375 ,  0.203125  ,  0.20605469, -0.02148438,\n",
       "       -0.24023438,  0.09765625,  0.07373047,  0.07519531, -0.12792969,\n",
       "       -0.24511719,  0.15820312, -0.12255859, -0.18261719, -0.15820312,\n",
       "       -0.265625  , -0.15917969, -0.19726562,  0.11621094,  0.10546875,\n",
       "        0.05395508, -0.20605469,  0.10302734,  0.11376953,  0.00265503,\n",
       "       -0.265625  ,  0.0559082 ,  0.06347656, -0.03540039, -0.11474609,\n",
       "        0.12109375, -0.15332031, -0.10009766, -0.04589844, -0.22460938,\n",
       "       -0.04882812,  0.15039062,  0.0625    , -0.07080078, -0.04443359,\n",
       "       -0.06542969,  0.07958984, -0.2265625 , -0.04077148,  0.02124023,\n",
       "       -0.44726562, -0.07226562,  0.08740234, -0.05419922,  0.01037598,\n",
       "        0.03662109, -0.01586914,  0.10546875, -0.33203125, -0.03027344,\n",
       "        0.09423828, -0.17382812, -0.04443359, -0.02331543, -0.17089844,\n",
       "        0.08691406,  0.06347656,  0.01092529,  0.22167969,  0.15820312,\n",
       "       -0.12792969,  0.31054688, -0.02392578, -0.0456543 , -0.12109375,\n",
       "        0.06542969, -0.11865234, -0.06030273,  0.14160156, -0.07275391,\n",
       "       -0.03295898,  0.42382812,  0.09228516,  0.03564453,  0.29882812,\n",
       "       -0.01611328,  0.2109375 , -0.11962891, -0.1328125 ,  0.03637695,\n",
       "       -0.17871094, -0.01623535,  0.13183594,  0.17773438,  0.03686523,\n",
       "        0.02905273,  0.2890625 , -0.02648926, -0.11132812,  0.02099609,\n",
       "       -0.0255127 , -0.0703125 , -0.17285156, -0.17871094, -0.01043701,\n",
       "        0.15917969, -0.140625  , -0.10839844, -0.00570679,  0.02001953,\n",
       "       -0.14941406, -0.08642578,  0.14355469, -0.08056641, -0.1484375 ,\n",
       "       -0.08007812, -0.4140625 , -0.18457031, -0.00970459, -0.046875  ,\n",
       "       -0.09326172,  0.03222656,  0.04052734, -0.01574707, -0.14746094,\n",
       "        0.02209473,  0.03955078,  0.00157166,  0.12109375,  0.13378906,\n",
       "       -0.23730469, -0.1328125 , -0.01519775, -0.09326172, -0.07910156,\n",
       "       -0.06542969,  0.18652344,  0.04589844,  0.15332031,  0.24023438])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification.\n",
    "\n",
    "We use Keras to train neural network part. The shape of input layer is (1500, 300). The input layer connects to three convolution layer of which the region size is 3, 4, 5 respectively. Each layer contains 256 filters, the stride is 1 and the activation function is 'RELU'. The result of CNN will feed into max pooling layer. Then, concat and flatten all filters. Use fully-connected neural networks with softmax to classify labels. Combining with dropout (0.2) to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = L.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "l_emd = L.Embedding(input_dim=len(word_index)+1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=MAX_SEQUENCE_LENGTH, \n",
    "                    trainable=False)(input_layer)\n",
    "l_conv1 = L.Conv1D(256, 3, padding='same', strides=1, activation='relu')(l_emd)\n",
    "l_maxpool1 = L.MaxPool1D(4)(l_conv1)\n",
    "\n",
    "l_conv2 = L.Conv1D(256, 4, padding='same', strides=1, activation='relu')(l_emd)\n",
    "l_maxpool2 = L.MaxPool1D(4)(l_conv2)\n",
    "\n",
    "l_conv3 = L.Conv1D(256, 5, padding='same', strides=1, activation='relu')(l_emd)\n",
    "l_maxpool3 = L.MaxPool1D(4)(l_conv2)\n",
    "\n",
    "l_combined = L.Concatenate()([l_maxpool1, l_maxpool2, l_maxpool3])\n",
    "flat = L.Flatten()(l_combined)\n",
    "drop = L.Dropout(0.2)(flat)\n",
    "\n",
    "output = L.Dense(y_train_vector.shape[1], activation='softmax')(drop)\n",
    "\n",
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(730), Dimension(256)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_conv3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6310 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "6310/6310 [==============================] - 141s 22ms/step - loss: 3.0265 - acc: 0.4609 - val_loss: 2.1184 - val_acc: 0.6200\n",
      "Epoch 2/15\n",
      "6310/6310 [==============================] - 133s 21ms/step - loss: 1.6038 - acc: 0.7228 - val_loss: 1.5463 - val_acc: 0.7560\n",
      "Epoch 3/15\n",
      "6310/6310 [==============================] - 133s 21ms/step - loss: 1.0307 - acc: 0.8349 - val_loss: 1.3315 - val_acc: 0.8280\n",
      "Epoch 4/15\n",
      "6310/6310 [==============================] - 133s 21ms/step - loss: 0.8303 - acc: 0.8868 - val_loss: 1.3390 - val_acc: 0.8430\n",
      "Epoch 5/15\n",
      "6310/6310 [==============================] - 132s 21ms/step - loss: 0.7646 - acc: 0.9144 - val_loss: 1.2889 - val_acc: 0.8500\n",
      "Epoch 6/15\n",
      "6310/6310 [==============================] - 132s 21ms/step - loss: 0.6952 - acc: 0.9195 - val_loss: 1.1756 - val_acc: 0.8560\n",
      "Epoch 7/15\n",
      "6310/6310 [==============================] - 134s 21ms/step - loss: 0.6632 - acc: 0.9235 - val_loss: 1.2036 - val_acc: 0.8540\n",
      "Epoch 8/15\n",
      " 512/6310 [=>............................] - ETA: 1:55 - loss: 0.7006 - acc: 0.9023"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-63ace3eb953f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# early stoppping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 15\n",
    "\n",
    "history = model.fit(train_X, \n",
    "          train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(val_x, val_y),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss for training dataset and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ee078d2156de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('{}/Google-News-300-loss-multilabel-{}.svg'.format(result_path, datetime.datetime.today()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('{}/Google-News-300-acc-multilabel-{}.svg'.format(result_path, datetime.datetime.today()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3355/3355 [==============================] - 27s 8ms/step\n",
      "Test score: 1.4517079295060318\n",
      "Test accuracy: 0.8229508198320243\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(data_test_X, data_test_y, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=data_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.zeros_like(y_pred)\n",
    "y_pred_label[np.arange(len(y_pred)), y_pred.argmax(1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3347, 73)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6235434717657604"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred_label, data_test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
